# DHCL + Lambda Annealing

### 核心结论

**实验结果清晰地证明了“自适应损失融合 (`λ`退火)”策略的优越性。** `OursV6` 不仅在**模型一致性**上达到了最佳表现，更重要的是，它成功地将一致性的提升**转化为了最终模型准确率的显著增长**，尤其是在最具挑战性的高异构性 (Non-IID) 场景下。这表明，在“全局对齐”和“本地适应”的权衡中，动态调整对齐强度是实现更优性能的关键。

---

### 1. 最终性能对比 (第50轮)

下表总结了在第50个通信轮次时，三个算法在不同数据异构程度（由 `alpha` 控制）下的核心指标。

| 异构程度 (α) | 算法 | 最终准确率 (Acc) | **准确率提升 (Δ vs V4)** | 模型方差 (Mean) [越低越好] | 全局原型标准差 (Std) [越低越好] |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **0.05 (极高)** | OursV4 | 66.97% | \- | 0.003233 | 1.00672 |
| | OursV5 | 67.44% | +0.47% | 0.003239 | 0.93532 |
| | **OursV6** | **68.17%** | **+1.20%** | **0.003296** | **0.70938** |
| **0.1 (高)** | OursV4 | 76.10% | \- | 0.003697 | 1.00676 |
| | OursV5 | 76.13% | +0.03% | 0.003703 | 0.92177 |
| | **OursV6** | **75.95%** | **-0.15%** | **0.003741** | **0.65501** |
| **0.3 (中等)** | OursV4 | 83.90% | \- | 0.004826 | 1.00671 |
| | OursV5 | 84.07% | +0.17% | 0.004818 | 0.89341 |
| | **OursV6** | **84.54%** | **+0.64%** | **0.004884** | **0.55652** |
| **0.5 (低)** | OursV4 | 87.69% | \- | 0.005401 | 1.00673 |
| | OursV5 | 87.72% | +0.03% | 0.005393 | 0.87582 |
| | **OursV6** | **88.17%** | **+0.48%** | **0.005437** | **0.50950** |

---

### 2. 学习动态：准确率演进过程

下表展示了算法在学习过程中的动态表现，可以揭示其收敛速度和稳定性。

| 异构程度 (α) | 算法 | 第10轮 Acc | 第30轮 Acc | 第50轮 Acc |
| :--- | :--- | :--- | :--- | :--- |
| **0.05 (极高)** | OursV4 | 49.73% | 62.37% | 66.97% |
| | OursV5 | 49.86% | 61.36% | 67.44% |
| | **OursV6** | **50.93%** | **63.65%** | **68.17%** |
| **0.1 (高)** | OursV4 | 54.65% | 70.24% | 76.10% |
| | OursV5 | 53.31% | 71.02% | 76.13% |
| | **OursV6** | **54.47%** | **70.15%** | **75.95%** |
| **0.3 (中等)** | OursV4 | 65.87% | 79.67% | 83.90% |
| | OursV5 | 65.92% | 78.89% | 84.07% |
| | **OursV6** | **66.63%** | **79.33%** | **84.54%** |
| **0.5 (低)** | OursV4 | 73.66% | 84.74% | 87.69% |
| | OursV5 | 74.36% | 84.67% | 87.72% |
| | **OursV6** | **74.34%** | **85.22%** | **88.17%** |

---

### 3. 深度分析

#### a. 准确率分析：`λ`退火策略全面胜出

*   **在高异构性 (α=0.05, 0.3) 下，`OursV6` 优势巨大**：在 `α=0.05` 时，`OursV6` 相比原始FAFI (`V4`) 实现了 **+1.20%** 的显著提升，并且也优于 `V5`。这证明了我们的核心假设：**训练早期强对齐、后期弱对齐**的策略，完美契合了高异构场景的需求。它首先强行将模型拉到同一个“起跑线”，然后在接近终点时允许它们进行个性化的“冲刺”。
*   **在低异构性 (α=0.5) 下，`OursV6` 依然是最佳选择**：即使在数据分布较为均衡的情况下，`OursV6` 仍然取得了最高的准确率 (88.17%)。这说明退火策略不仅解决了高异构的问题，其“后期微调”的特性也很好地保留了模型适应本地数据的能力，找到了比固定`λ`的`V5`更优的平衡点。
*   **唯一的例外 (α=0.1)**：在此设定下，`OursV6` 的最终表现略低于V4和V5。这可能是由于超参数（初始`λ`、退火速率）与该特定数据分布的“共振点”未能完美匹配。但考虑到其差距极小 (-0.15%) 且在其他所有场景中均获胜，这更像是一个需要微调的角落案例，而非策略本身的失败。
*   **学习动态**：从学习过程来看，`OursV6` 在**几乎所有场景的早期阶段（第10轮）就取得了领先**，这表明强初始对齐策略能加速模型进入一个更优的收敛轨道。

#### b. 模型一致性分析：达到了前所未有的对齐水平

这是最令人振奋的结果，它从根本上验证了我们方法的有效性。

*   **全局原型标准差 (`g_protos_std`) 大幅降低**：
    *   在**所有**alpha设置下，`OursV6` 的 `g_protos_std` 都达到了**最低值**，远低于V5，更是将V4远远甩开。例如在 `α=0.5` 时，`g_protos_std` 从V4的 `1.006` 降至 `0.509`，**几乎降低了50%**！
    *   这无可辩驳地证明了 `λ` 退火策略是实现客户端模型（原型）对齐的**极其有效**的手段。

*   **模型参数方差 (Model Variance) 的微妙变化**：
    *   `OursV6` 的模型方差略高于V4和V5。这**完全符合预期，并且是一个积极信号**！我们的策略是：在保证**分类决策核心（原型）高度一致**的前提下，允许**特征提取器（模型的其余参数）**在后期有更大的自由度去适应本地数据，使得最终的参数呈现出有益的“个性化”。因此，我们可以得出结论：OursV6 成功地做到了 “特征空间结构一致，但模型具体参数存有个性” 的理想状态。