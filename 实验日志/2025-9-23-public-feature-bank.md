# 2025/9/23 public feature bank

服务器将扮演一个“教师”的角色，在联邦学习开始前，利用 public_set 短暂地训练一个模型。这个模型的唯一目的就是学习 public_set 的基本特征分布，然后用它来生成真正有意义的、源于内部数据的公共特征库。

---

### 实验数据对比分析

## **实验设置概述**

*   **数据集：** CIFAR-10
*   **模型：** ResNet18
*   **客户端数量：** 5
*   **本地训练轮次 (local_epochs)：** 1
*   **联邦学习轮次 (num_rounds)：** 35/50
*   **Non-IID程度 (`alpha`)：** 0.5 (较弱非IID), 0.3 (中等非IID), 0.05 (强非IID)
*   **对比学习温度 (`contrastive_temperature`)：** 0.5
*   **公共数据比：** 0.1
*   **特征库大小：** 4096
*   **服务器教师模型的预训练轮数：** 20


### 实验结果分析表

| Non-IID Level (alpha) | Round | **OursV4** (No Bank) | **OursV5** (With Bank) | Performance Delta (V5 - V4) |
| :--- | :---: | :---: | :---: | :---: |
| **0.5 (弱)** | 0 | **46.21%** | 38.13% | -8.08% |
| | 10 | **76.59%** | 72.43% | -4.16% |
| | 20 | **83.47%** | 80.14% | -3.33% |
| | 35 | **87.07%** | 84.70% | -2.72% |
| **0.3 (中)** | 0 | **43.16%** | 35.29% | -7.87% |
| | 10 | **74.55%** | 62.50% | -12.05% |
| | 20 | **81.92%** | 72.67% | -9.25% |
| | 35 | **86.02%** | 77.99% | -8.03% |
| **0.1 (强)** | 0 | **41.18%** | 24.22% | -16.96% |
| | 10 | **70.36%** | 53.56% | -16.80% |
| | 20 | **78.39%** | 64.67% | -13.72% |
| | 35 | **83.73%** | 71.17% | -12.56% |
| **0.05 (极强)** | 0 | **42.17%** | 14.17% | -28.00% |
| | 10 | **70.82%** | 35.88% | -34.94% |
| | 20 | **79.11%** | 44.88% | -34.23% |
| | 35 | **83.67%** | 49.92% | -33.75% |

---

### 深入分析：假设的证实与失败的根源

**核心结论：** 我们确实创建并引入了一个有语义价值的全局负样本库。然而，实验结果表明，我们对“如何使用这个库”的**核心假设是错误的**。新方法（OursV5）的性能显著低于基线（OursV4），并且数据的Non-IID程度越强（`alpha`越小），性能下降越剧烈。

猜想：在高度异构的环境下，将强烈的本地监督信号（来自`cls_loss`）与同样强烈的全局对齐信号（来自`contrastive_loss`）直接相加，会导致“破坏性的梯度干扰”（Destructive Gradient Interference）。

让我们以最极端的 `alpha=0.05` 场景为例来剖析这个问题：

1.  **客户端的目标是什么？**
    *   一个客户端的本地数据集可能只包含**类别1（猫）**和**类别7（马）**的图片。
    *   它的**本地分类损失 (`cls_loss`)** 的目标非常明确和狭隘：学习一个特征提取器，能够将“猫”的特征与“马”的特征在空间中尽可能地分开。这是它的**首要任务**。

2.  **全局特征库引入了什么？**
    *   我们的服务器教师模型在包含所有10个类别（飞机、汽车、鸟...）的公共数据上进行了训练。
    *   因此，公共特征库提供了一个**全局参照系**，其中包含了所有10个类别的特征表示。
    *   **对比损失 (`contrastive_loss`)** 的目标是：将本地的“猫”和“马”的特征，从特征库中所有10个类别的特征（飞机、汽车、鸟...）旁推开。

3.  **冲突在哪里？**
    *   `cls_loss` 的梯度说：“动用你所有的网络参数，把全部精力都放在‘区分猫和马’这个精细的任务上！”
    *   `contrastive_loss` 的梯度说：“别只顾着猫和马！你必须同时确保你学到的猫/马特征，还要远离飞机、汽车、鸟、狗的特征！”

    对于客户端模型而言，这是一个极其矛盾的优化目标。为了满足全局对比损失，它需要学习一些对区分“马”和“鸟”很重要的通用特征，但这部分模型能力（参数）本可以被用来更好地学习区分“马”和“白色马头背景下的白云”这种更细微的本地任务。

    **结果就是：** 模型的优化过程被撕裂了。它既没有完美地完成区分本地类别的首要任务，也没有完全对齐到全局特征空间，最终学到的特征表示是一个“四不像”的糟糕妥协。

因此：

*   当 **`alpha = 0.5`** 时，本地数据分布与全局分布差异不大，客户端本身就有很多类别。因此，`cls_loss`和`contrastive_loss`的目标**大致相同**，梯度冲突较小。所以我们看到性能下降不明显，在训练后期甚至追平了。
*   当 **`alpha = 0.05`** 时，本地与全局的分布差异**达到最大**。`cls_loss`的目标变得极度专业化和狭隘，与`contrastive_loss`的全局化目标**几乎正交**。梯度冲突最大化，导致了灾难性的性能崩溃。

---

### 下一步方向：从“信号混合”到“分阶段优化”


直接的`loss`相加是行不通的。下一步的核心思想是**解耦（Decouple）** 这两个相互冲突的目标。

**具体方案：两阶段本地训练 (Two-Stage Local Training)**

我们不再让模型同时学习两个冲突的目标，而是分步进行。在每个客户端的本地训练过程中，我们执行以下两个阶段：

**阶段一：全局特征对齐 (Global Feature Alignment)**

*   **目标**: 让客户端模型的“世界观”先向全局看齐。
*   **方法**: 在最初的 N 个 `local_epochs`（例如，N可以设为总轮数的前20%），客户端**只使用对比损失进行训练**。
    *   `total_loss = contrastive_loss(local_features, public_feature_bank)`
*   **效果**: 在这个阶段，模型不关心本地分类任务，它的唯一目标是学习一个通用的特征提取器，其输出的特征空间结构与教师模型所定义的全局空间结构相似。这相当于在本地“预训练”或“热身”，让模型先具备一个良好的、全局一致的起点。

**阶段二：本地任务微调 (Local Task Fine-tuning)**

*   **目标**: 在已经对齐的特征空间基础上，高效地学习本地的分类任务。
*   **方法**: 在后续的 M 个 `local_epochs` 中，我们**只使用标准的FAFI损失**（或者只用`cls_loss`和`proto_loss`进行微调）。
    *   `total_loss = cls_loss + proto_loss + ...` (可以暂时关闭`contrastive_loss`，或者用一个极小的权重)
*   **效果**: 由于模型已经有了一个很好的特征基础，这个阶段的微调会变得非常高效。模型可以在不破坏已对齐的全局结构的前提下，快速学习区分本地类别的细微差别。

**为什么这个方案有希望成功？**

这个方案直接解决了梯度冲突问题。它将一个复杂的、多目标的优化问题分解成了两个更简单的、单目标的子问题，并按顺序执行。这在机器学习中是一种非常经典且有效的思想（例如，预训练+微调）。

**接下来的实验计划：**

1.  **实现两阶段训练逻辑**：修改 `ours_local_training.py`，加入一个`if/else`块来区分训练阶段，并根据当前`epoch`数选择不同的损失函数组合。
2.  **设置超参数**：引入一个新的配置项，如 `alignment_epochs`，来控制第一阶段的训练轮数。
3.  **重新运行实验**：首先在最具挑战性的 `alpha=0.05` 上运行，观察新方案（我们称之为`OursV6`）是否能显著缩小与`OursV4`的差距，甚至反超。
4.  **分析与迭代**：如果成功，我们可以进一步调整`alignment_epochs`的比例，找到最优的平衡点。
