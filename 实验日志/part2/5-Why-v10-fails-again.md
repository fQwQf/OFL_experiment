我将sigma的lr设置成了一般lr的0.01倍，结果如上。

非常好！这组实验日志信息量极大，清晰地展示了为`sigma`参数设置专属学习率后的效果，并引出了一个更深层次、非常有价值的结论。

让我们系统地进行分析。

### 实验结果总结与数据分析表格

首先，我们整理关键数据。V9的`lambda`是基于数据熵的**静态先验值**，而V10的`Effective Lambda`是**动态学习**的结果。

**实验设置:**
*   **数据集:** CIFAR-100 (100个类别)
*   **异构性:** `alpha = 0.05` (极度Non-IID，每个客户端的数据分布差异巨大)
*   **本地训练:** `local_epochs = 1` (极短的本地训练)
*   **V10 `sigma_lr`:** `0.0005` (是基础学习率 `0.05` 的0.01倍)

#### 表1：V9 (自适应策略) vs V10 (学习策略) 对比

| 评价指标 | OursV9 (自适应λ) | OursV10 (学习得到的λ) | 分析与结论 |
| :--- | :--- | :--- | :--- |
| **最终准确率 (第99轮)** | **32.89%** | **23.94%** | **V9 胜出**。V9的性能显著优于V10。 |
| **Lambda 策略** | 基于数据熵计算，**客户端专属**且**全程固定**。 | 从梯度中**动态学习**，每个客户端在**每一轮**都会更新。 | V9是“授之以鱼”（直接给一个好策略），V10是“授之以渔”（让它自己学）。 |
| **Lambda 值** | 客户端专属，值域为 **[13.5, 14.9]** (非常高！) | 从`1.0`开始，**缓慢增长**到 **[8.5, 10.3]** 的范围。 | V9从一开始就采用了非常强的对齐策略。V10也在向高`lambda`学习，但从未达到V9的水平。 |
| **稳定性** | 完美稳定（设计如此）。 | **优化过程稳定**。`Effective Lambda`平滑增长，没有出现上次的爆炸或剧烈震荡。 | **成功！** 您对`sigma_lr`的修改**完全解决了V10的优化不稳定性问题**。 |

#### 表2：详细数据追踪（选取代表性轮次）

| Round | V9 Test Acc. | V10 Test Acc. | V9 Lambda (Client 0/4) | V10 Eff. Lambda (Client 0/4) |
| :--- | :--- | :--- | :--- | :--- |
| 0 | 3.86% | 1.11% | 13.51 / 14.90 | 1.04 / 1.07 |
| 9 | 10.12% | 8.25% | 13.51 / 14.90 | 1.47 / 1.89 |
| 30 | 17.89% | 13.42% | 13.51 / 14.90 | 5.68 / 6.19 |
| 60 | 26.17% | 19.21% | 13.51 / 14.90 | 8.24 / 9.49 |
| 99 | **32.89%** | **23.94%** | 13.51 / 14.90 | 8.53 / 10.38 |

### 发生了什么？深入分析

这次的实验结果非常清晰且具有启发性。

1.  **成功之处：V10的优化确实被修复了。**
    对比上次的日志，这次V10的`Effective Lambda`表现得非常“健康”。它从一个无偏的初始值（约1.0）开始，随着训练的进行而平滑、稳定地增长。这证明了**为`sigma`参数设置一个独立的、更小的学习率是解决其优化稳定性的正确方法**。您成功地让V10“学会了学习”。

2.  **核心问题：V9的“先验知识”在当前场景下优于V10的“在线学习”。**
    您问：“是不是单纯地将V10原论文的理念用于联邦学习不能取得预期的效果？”
    **更精确的答案是：在一个极度异构 (`alpha=0.05`)、类别极多 (CIFAR-100)、且本地训练极不充分 (`local_epochs=1`) 的“地狱模式”下，V10的在线学习能力跟不上V9基于数据分布给出的优秀“先验指导”。**

    *   **V9的洞察力：** V9的熵计算方法发现，在CIFAR-100 `alpha=0.05`这种极端场景下，客户端的数据分布虽然有差异，但它们的共同点是**都非常不均衡、信息量有限**。因此，它为所有客户端都给出了一个**非常高**的`lambda`值（13.5到14.9之间）。这个策略的潜台词是：“你们本地的数据都太少了，别太相信自己的梯度了，给我狠狠地向着全局最优的ETF结构对齐！”
    *   **V9策略的有效性：** 实验结果（V9达到32.89%的准确率）证明，在这个极端场景下，**强制强对齐是一个非常有效的策略**。它牺牲了一部分本地化的能力，但换来了模型在全局特征空间上的一致性，避免了灾难性的分歧。
    *   **V10的“学习困境”：** V10虽然在稳定地学习，但它的学习速度和最终收敛到的值都落后于V9的“先验设定”。它最终学到的`lambda`值（8.5-10.3）虽然也不低，但始终没有达到V9设定的13-15的“最优区间”。这可能是因为在每轮只有一个epoch的梯度信号下，模型没有足够的信息来“领悟”到需要如此强的对齐力度。

### 结论与下一步建议

**结论：**
您的实验揭示了一个深刻的观点：在联邦学习的极端场景中，一个基于数据分布的、看似简单的**启发式规则（V9）**，其效果可能超过一个需要从零开始、在有限信息下进行在线学习的**理论最优方法（V10）**。

这并不意味着V10是错误的，而是说明**它的学习能力受到了联邦学习环境（特别是`local_epochs=1`）的严重制约**。V9相当于给学生划了重点，而V10需要自己摸索重点，但在每次只看一页书的情况下，V10的摸索效率太低了。

**如何让V10发挥潜力？（实验建议）**

1.  **“预热”V10：将V9的智慧赋予V10。**
    *   **思路：** 这是一个非常有前景的混合策略。不要让V10从`lambda=1`的无知状态开始，而是用V9计算出的`lambda`值**作为V10的初始值**。
    *   **实现：** 在`OneshotOursV10`中，为每个客户端计算一次`adaptive_lambda`。然后，在创建`log_sigma_sq_local`和`log_sigma_sq_align`时，将它们的初始值设置为 `torch.tensor(log(adaptive_lambda))` 和 `torch.tensor(0.0)`。这样，初始的`Effective Lambda`就等于V9的设定值。
    *   **预期：** V10从一个非常好的起点开始，然后利用其学习能力进行微调。这很可能会让V10最终超越V9。

2.  **给予V10更充分的学习环境：**
    *   **思路：** 如果保持V10从零开始学习，那么需要给它更稳定、更丰富的梯度信息。
    *   **实现：** 将`local_epochs`从1增加到5或10。
    *   **预期：** 在更多的本地迭代中，V10的优化器有更充分的机会来调整`sigma`参数，从而可能学习到更高的、更接近V9的`lambda`值，并提升性能。

3.  **微调V10的学习速度：**
    *   **思路：** 当前的`sigma_lr=0.0005`虽然稳定，但可能学习得太慢。
    *   **实现：** 尝试稍微提高一点`sigma_lr`，比如`0.001`或`0.002`，观察`Effective Lambda`的增长速度和最终的准确率。这是一个新的需要微调的超参数。

总之，您当前的实验结果非常有价值。它清晰地展示了V9策略在极端Non-IID场景下的鲁棒性，同时也暴露了V10在信息极其稀疏的环境下学习的局限性。下一步的混合策略或增加本地训练将是非常值得尝试的探索方向。