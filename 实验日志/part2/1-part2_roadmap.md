# part2总体方案

目前的v7还是停留在 L_total = L_local + λ * L_align 一个本地loss加一个全局对齐通过一个参数简单相加，这是十分笨拙的。对此有这样几种优化方案：

### A：根据数据调整λ

我们不再使用一个全局统一的λ，而是每个客户端根据自己的本地数据特征，动态地、独立地决定自己的对齐强度λ_i。在本地训练开始前，每个客户端i计算一个描述其数据异质性的指标，然后将其映射到一个λ_i值。最简单直接的指标是本地类别分布的熵。

1.  计算熵: 客户端i统计其本地数据中每个类别的样本数量，计算出一个概率分布p_i，然后计算其香农熵H(p_i)。高熵意味着该客户端的数据分布相对均衡，低熵意味着数据分布高度倾斜，只包含少数几个类别。
2.  映射λ_i: 我们设计一个映射函数 λ_i = f(H(p_i))。最符合逻辑的假设是：
    *   高熵的本地学习方向与全局目标偏差不大，可以给予更强的对齐约束（较大的λ_i），让它为全局共识做出更大贡献。
    *   低熵的本地知识虽然有偏，但可能包含了细粒度信息，我们应该给予更弱的对齐约束（较小的λ_i），允许它更多地保留本地特性。

FedPref: Federated Learning Across Heterogeneous Multi-objective Preferences (Hartmann et al., 2025, arXiv),https://doi.org/10.48550/arXiv.2501.13604  

这篇论文提出，在联邦学习中，不同的客户端可能对学习目标有不同的偏好（例如，有的更看重准确率，有的更看重公平性）。他们设计了一个框架，服务器学习一个在帕累托前沿上的模型集合，客户端可以根据自己的偏好选择最适合自己的模型。FedPref证明了客户端个性化目标是FL中一个前沿且合理的方向。  
我们需要一个更明确的方向。我们不是人为主观地定义超参数，而是通过本地数据熵，客观地、自动地推断出客户端对于目标的偏好，并据此设定个性化的λ_i。

### B：服务器端自适应锚点

这是我们从FedTGP中得到的启发，服务端接收所有客户端的本地原型，然后自己再次学习出一个全局模型，并在这个时候加一个正则化项拉向ETF。

这个过程发生在服务器端的聚合阶段内部，因此不违背OFL原则。

1.  客户端: 正常执行V7的本地训练，对齐到一个初始的、固定的ETF锚点，然后上传其最终的本地原型P_i。
2.  服务器端 (聚合阶段):
    1.  接收到所有P_i。
    2.  初始化一个可学习的全局原型P_global（可以使用所有P_i的平均值，或ETF锚点作为初始状态）。
    3.  开启一个内部的、迷你的优化循环（例如，10-50个step）。在每个step中，计算一个服务器端损失函数L_server，并用它来更新P_global。
    4.  L_server由两部分组成：
        -   L_contrastive (源于FedTGP): 将P_global向所有客户端上传的P_i拉近，并与其他类别的P_i推开。  
        -   L_etf_reg : 增加一个正则化项将P_global拉向理论最优的ETF结构。这确保P_global在适应现实的同时，不会偏离一个良好的几何结构。  
3.  最终模型: 经过服务器端优化后的P_global，将与融合后的特征提取器一起，构成最终的、最强的全局模型。

FedTGP: Trainable Global Prototypes with Adaptive-Margin-Enhanced Contrastive Learning for Data and Model Heterogeneity in Federated Learning (Zhang et al., 2024, AAAI) , https://doi.org/10.48550/arXiv.2401.03230  
FedTGP是该方向的开创者。它首次提出，服务器不应该只是简单地平均原型，而应该拥有自己的一组可学习的全局原型 (TGP)，并通过一种自适应边距的对比损失，在服务器端对这些全局原型进行优化。我们直接借鉴FedTGP的“聚合即优化”这一思路，加入了L_etf_reg，一个将可学习的全局原型拉向我们理论最优ETF结构的正则化项。

---

### C：梯度投影与对齐

L_local和L_align的梯度冲突可能会导致性能下降。

在客户端的每一个本地训练步骤中：
1.  计算两个独立的梯度：
    *   g_local = ∇ L_local (本地任务梯度)
    *   g_align = ∇ L_align (全局对齐梯度)
2.  检查冲突: 计算这两个梯度的余弦相似度 cos(g_local, g_align)。
3.  执行几何修正:
    *   如果 cos > 0 (方向一致): 两个梯度可以安全地相加并应用。
    *   如果 cos < 0 (方向冲突): 执行梯度投影：将g_local投影到g_align的正交补空间上，即 g'_local = g_local - proj(g_local, onto: g_align)。这个操作会移除g_local中与g_align冲突的分量，同时保留其所有不冲突的更新。
4.  最终更新: 应用修正后的g'_local和原始的g_align。

Gradient Surgery for Multi-Task Learning (Yu et al., 2020, NeurIPS) , arXiv:2001.06782 [cs.LG] https://doi.org/10.48550/arXiv.2001.06782 

这篇论文提出了PCGrad (Projecting Conflicting Gradients)算法。全局对齐和本地学习的两个梯度可能冲突，如果不同任务的梯度方向冲突（余弦相似度为负），PCGrad会将其中一个任务的梯度，投影到另一个任务梯度的正交补空间上，从而精确地消除梯度中的冲突分量，同时保留所有不冲突的、有益的更新。