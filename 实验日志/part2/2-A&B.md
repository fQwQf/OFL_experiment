# A&B

我们设计了 V9 ，并将方案A,B融入其中，并设计了以下消融实验：


下表是我们在alpha=0.05的前提下，对四种V9消融实验组合在第49轮（最终轮）的指标进行的比较：

| 组合 (Plan A + Plan B) | inter_client_proto_std | g_protos_std | 最终准确率 |
| :--- | :--- | :--- | :--- |
| V7 (A-, B-) [基线] | 0.0419 | 0.9136 | 58.77% |
| 纯方案 A (A+, B-) | 0.0521  | 0.9176 | 59.04% |
| 纯方案 B (A-, B+) | 0.0406 | 0.9153 | 56.87% |
| 方案 A + B (A+, B+) | 0.0494 | 0.9207 | 58.21% |
| (参考) V4 (FAFI原文) | ~0.055+ | ~1.006 | ~57.74% |


显然 Plan A 的优化效果是成功的，而 Plan B则只有负效果。同时 inter_client_proto_std 和 g_protos_std 则在数值上有值得注意之处。我们将试着分析一下这两个数据，为效果给出猜想。

为了理解上表的深刻含义，我们要将这两个指标的物理意义理清。

*   inter_client_proto_std (直接不一致性)
    *   它测量的是在服务器进行任何聚合操作之前，所有客户端上传的本地原型，在特征空间的平均离散程度。
    *   代码： torch.std(local_protos, dim=0).mean()
    *   这是一个直接的不一致性度量。值越高，说明客户端模型之间的原型差异越大。

*   g_protos_std (间接不一致性)
    *   它测量的是所有本地原型被聚合之后，得到的最终的全局原型的内部结构性或确定性。
    *   代码： torch.std(g_protos)
    *   这是一个间接的、推断性的指标。
        *   如果本地原型的观点高度一致，最终的结果充满确定信息 -> g_protos_std低。
        *   如果本地原型的观点随机混乱，最终的结果充满了不确定性 -> g_protos_std高。

观察数据，纯方案A在直接不一致性 (inter_client_proto_std) 上表现出有控制的、中等程度偏高，但在间接不一致性 (g_protos_std) 上表现出决定性的“好”。我们可以这么说：A在保持一致性的前提下展现出有益的多样性。  

相比之下，B通过服务器端优化，强行将所有模型拉到最齐，获得了最低的inter_client_proto_std（0.0406）。绝对一致可能使得低熵客户端的细粒度数据被掩盖了，最终准确率下降。

B的失败，也意味着C方案极有可能会失败。这两个方案都追求绝对一致，本质是共通的。

我们的研究始于通过对齐锚点解决模型不一致性。然而，现在我们发现，在OFL中，最优的解决方案并非追求极致的一致性。 而是要将其不一致从无序的、破坏性的差异，转化为一种有序的、有益的多样性。通过允许低熵客户端保留其独特性，同时让高熵客户端维护核心共识，才能为后续的服务端集成提供了信息量丰富的输入，从而实现了全局性能的最优化。
