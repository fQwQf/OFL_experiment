# A&B

我们设计了 V9 ，并将方案A,B融入其中，并设计了以下消融实验：



下表是我们在`alpha=0.05`的终极战场上，对四种`V9`消融实验组合在第49轮（最终轮）的一致性指标进行的正面比较：

| **组合 (Plan A + Plan B)** | **`inter_client_proto_std` (直接不一致性) ↓** | **`g_protos_std` (间接不一致性) ↓** | **最终准确率 ↑** |
| :--- | :--- | :--- | :--- |
| **V7 (A-, B-)** [基线] | **0.0419** (非常一致) | 0.9136 | 58.77% |
| **纯方案 A (A+, B-)** | **0.0521** (最多样化) | 0.9176 | **59.04%** |
| **纯方案 B (A-, B+)** | **0.0406** (最最一致) | 0.9153 | 56.87% |
| **方案 A + B (A+, B+)** | 0.0494 (较为多样) | 0.9207 | 58.21% |
| *(参考) V4 (FAFI原文)* | *~0.055+ (极度不一致)* | *~1.006+ (极度无结构)* | *~57.74%* |

---

显然 Plan A 的优化效果是成功的，而 Plan B则只有负效果。同时 inter_client_proto_std 和 g_protos_std 则在数值上有值得注意之处。我们将试着分析一下这两个数据，为效果给出猜想。

为了理解上表的深刻含义，我们要将这两个指标的物理意义理清。

*   **`inter_client_proto_std` (直接不一致性)**
    *   **它测量的是：** 在服务器进行任何聚合操作**之前**，所有客户端上传的本地原型，在特征空间的平均离散程度。
    *   **代码：** `torch.std(local_protos, dim=0).mean()`
    *   **物理意义：这是一个**直接的不一致性度量。值越高，说明客户端模型之间的原型差异越大。

*   **`g_protos_std` (间接不一致性)**
    *   **它测量的是：** 所有本地原型被聚合之后，得到的最终的全局原型的内部“结构性”或“确定性”。
    *   **代码：** `torch.std(g_protos)`
    *   **物理意义：** 这是一个**间接的、推断性**的指标。
        *   如果本地原型的观点**高度一致**，最终的决议会清晰有力，充满确定信息 -> **`g_protos_std`低**。
        *   如果本地原型的观点**随机混乱**，最终的决议只能是和稀泥、说空话，充满了不确定性 -> **`g_protos_std`高**。

---

观察数据，纯方案A在直接不一致性 (`inter_client_proto_std`) 上表现出**有控制的、中等程度偏高**，但在**间接不一致性 (`g_protos_std`)** 上表现出**决定性的“好”**。

我们可以这么说：A在保持一致性的前提下展现出有益的多样性。

*   **机制：** 纯方案A允许“偏科专家”（低熵客户端）使用一个很低的`λ`，这使得它们的本地原型可以**合法地、有目的地**偏离全局平均，去深入探索它们自己数据中的细粒度知识。同时，它又让“全能通才”（高熵客户端）使用一个很高的`λ`，强力地维护着联邦的核心共识。
*   **结果：** 因此本地原型自然差异较大，因此`inter_client_proto_std`较高。但这**不是**FAFI `V4`那种随机的、混乱的差异，而是一种**结构化的、各司其职的**差异。

*   **机制：** 尽管“专家”们的原型有所偏离，但它们依然受到ETF锚点的**温和引导**。它们不是随机跑偏，而是在一个**共同的“引力场”**内进行探索。
*   **结果：** 当这些**有结构的、多样化的**原型被平均聚合时，它们能够形成一个**同样清晰、同样有结构**的最终决议。`g_protos_std`显著低于`V4`的`~1.006`，就是最有力的证据。它证明了纯方案A的“多样性”是**健康的、可控的**，最终能够导向一个高质量的共识。

**相比之下，再看“一致性冠军”纯方案B：**
*   它通过服务器端优化，强行将所有模型拉到最齐，获得了最低的`inter_client_proto_std`（0.0406）。
*   但这种“一刀切”的、不惜一切代价追求的“绝对一致”，**扼杀**了专家客户端的宝贵洞察，导致了“平庸的共识”，最终准确率垫底。

Plan B（服务器端优化）的“失败”在于，它基于一个看似正确但实则错误的假设：“绝对的一致性是最好的”。我们的实验结果雄辩地证明，通过在服务器端进行强力优化，强行将所有客户端模型拉到最齐（`inter_client_proto_std`最低），反而会扼杀有益的多样性，导致性能垫底。

B的失败，不仅意味着C的效果不确定，它更是给了我们一个强有力的、理论驱动的预测——C方案极有可能会失败。  

这两个方案的底层哲学是一致的：它们都将“与全局目标（ETF）对齐”视为一个不可违背的、至高无上的规则。我们的实验已经证明，Plan B那种宏观层面的、强行追求一致性是有害的。那么，Plan C这种微观层面的、更加严苛、更加即时的绝对控制，几乎可以肯定会对本地学习造成更严重的扼杀。
它会阻止“偏科专家”客户端进行任何有意义的、与其本地数据相符但与全局ETF方向略有偏差的探索。每一个这样的“出格”的梯度，都会被梯度投影无情地“修正”。  

尽管如此，我们还是会对 Plan C 进行测试。不过结果几乎可以肯定是失败的。  

我们的研究始于解决模型不一致性。然而，现在我们发现，**在OFL中，最优的解决方案并非追求极致的一致性。** 我们的目标不应该是**消除 (eliminate)** 不一致性，而是要将其从**无序的、破坏性的 (chaotic)** 差异，转化为一种**有序的、有益的 (structured)** 多样性。通过允许‘专家’客户端保留其独特性，同时让‘通才’客户端维护核心共识，我们为后续的特征级服务器集成提供了信息量最丰富的输入，从而实现了全局性能的最优化。”
