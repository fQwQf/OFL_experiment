之前对于 lambda 的分析不够深入。为了研究更好的 lambda 自适应方案，我们对其深入研究：

我们将lambda分别设置为	1.0	2.5	5.0	10.0	20.0	50.0，分别对CIFAR-10, α=0.05 ， SVHN, α=0.05和CIFAR-10, α=0.3进行实验。结果如下：

#### **表1：CIFAR-10, α = 0.05 (极高异构 / “冲突区”)**

| `lambda_initial` | **最终准确率 (Acc) ↑** | **`inter_client_proto_std` (直接不一致性) ↑** | **`g_protos_std` (间接不一致性) ↓** |
| :--- | :--- | :--- | :--- |
| **1.0** | 58.89% | 0.0176 | 0.9871 |
| **2.5** | 57.44% | 0.0263 | 0.9585 |
| **5.0** | 58.77% | 0.0419 | 0.9136 |
| **10.0** | 59.38% | 0.0711 | 0.8736 |
| **20.0** | **59.68%** | 0.1172 | 0.5968 |
| **50.0** | 59.39% | 0.1727 | 0.5028 |

#### **表2：SVHN, α = 0.05 (高异构 / “协同区”)**

| `lambda_initial` | **最终准确率 (Acc) ↑** | **`inter_client_proto_std` (直接不一致性) ↑** | **`g_protos_std` (间接不一致性) ↓** |
| :--- | :--- | :--- | :--- |
| **1.0** | 51.04% | 0.0695 | 0.8833 |
| **2.5** | 50.74% | 0.1355 | 0.7373 |
| **10.0** | 50.64% | 0.2770 | 0.3985 |
| **20.0** | **51.07%** | 0.3050 | 0.3024 |
| **50.0** | 49.46% | 0.2979 | 0.2250 |

#### **表3：CIFAR-10, α = 0.3 (中等异构 / “协同区”)**

| `lambda_initial` | **最终准确率 (Acc) ↑** | **`inter_client_proto_std` (直接不一致性) ↑** | **`g_protos_std` (间接不一致性) ↓** |
| :--- | :--- | :--- | :--- |
| **1.0** | 69.97% | 0.0125 | 0.9922 |
| **2.5** | 70.34% | 0.0146 | 0.9712 |
| **5.0** | 69.96% | 0.0197 | 0.9371 |
| **10.0** | 70.88% | 0.0297 | 0.8736 |
| **20.0** | 70.31% | 0.0461 | 0.7580 |
| **50.0** | **71.44%** | 0.0743 | 0.5028 |

---

在**所有三个场景**中，我们都清晰地观察到了：随着`lambda`的增加，`inter_client_proto_std`（斗争的激烈程度）**普遍上升**，而`g_protos_std`（共识的最终质量）**普遍下降**。这与2-2的观察相同。


无论是CIFAR-10还是SVHN，当alpha = 0.05时，性能都在1.0和20.0处较高。此时从经验来说，采用利用熵映射 lambda 至1.0 - 20.0是可行的。然而，随着 alpha 上升，最高性能达峰 lambda 会提升。我们证明了不存在一个全局最优的固定`λ`，然而现在的方法，只能说在对于像CIFAR10和SVHN这样的简单数据集是在低alpha下的一个凭经验得到的较优解。它无法保证在其他数据集或异构等级下也是最优的。这显然不能让人满意。
