# 2025/9/23 public feature bank

在这个实验中，服务器将扮演一个“教师”的角色，在联邦学习开始前，利用 public_set 的一部分短暂地训练一个模型。这个模型的唯一目的就是学习 public_set 的基本特征分布，然后用它来生成真正有意义的、源于内部数据的公共特征库。

原始实验数据见[public_feature_bank.txt](public_feature_bank.txt)。

### 实验结果

| Non-IID Level (alpha) | Round | OursV4 (No Bank) | OursV5 (With Bank) | Performance Delta (V5 - V4) |
| :--- | :---: | :---: | :---: | :---: |
| 0.5 (弱) | 0 | 46.21% | 38.13% | -8.08% |
| | 10 | 76.59% | 72.43% | -4.16% |
| | 20 | 83.47% | 80.14% | -3.33% |
| | 35 | 87.07% | 84.70% | -2.72% |
| 0.3 (中) | 0 | 43.16% | 35.29% | -7.87% |
| | 10 | 74.55% | 62.50% | -12.05% |
| | 20 | 81.92% | 72.67% | -9.25% |
| | 35 | 86.02% | 77.99% | -8.03% |
| 0.1 (强) | 0 | 41.18% | 24.22% | -16.96% |
| | 10 | 70.36% | 53.56% | -16.80% |
| | 20 | 78.39% | 64.67% | -13.72% |
| | 35 | 83.73% | 71.17% | -12.56% |
| 0.05 (极强) | 0 | 42.17% | 14.17% | -28.00% |
| | 10 | 70.82% | 35.88% | -34.94% |
| | 20 | 79.11% | 44.88% | -34.23% |
| | 35 | 83.67% | 49.92% | -33.75% |

### 分析

我们确实创建并引入了一个有语义价值的全局负样本库。然而，实验结果表明，我们对“如何使用这个库”的核心假设是错误的。新方法的性能显著低于基线，并且数据的Non-IID程度越强（`alpha`越小），性能下降越剧烈。

猜想：在高度异构的环境下，将强烈的本地监督信号（来自`cls_loss`）与同样强烈的全局对齐信号（来自`contrastive_loss`）直接相加，会导致破坏性的梯度冲突。

一个客户端的本地数据集可能只包含少部分类别的数据。本地分类损失 (`cls_loss`) 的目标非常明确和狭隘：学习一个特征提取器，能够将特征在空间中尽可能地分开。这是它的首要任务。  

我们的服务器教师模型在包含所有类别的公共数据上进行了训练。因此，公共特征库提供了一个全局参照系，其中包含了所有类别的特征表示。对比损失 (`contrastive_loss`) 的目标是：将本地数据的特征，从特征库中所有类别的特征旁推开。  

对于客户端模型而言，这是一个极其矛盾的优化目标。为了满足全局对比损失，它需要学习一些对区分未涉及的类别很重要的通用特征，但这部分模型能力（参数）本可以被用来更好地学习区分更细微的本地任务。  

结果就是： 模型的优化过程被撕裂了。它既没有完美地完成区分本地类别的首要任务，也没有完全对齐到全局特征空间，最终学到的特征表示是一个“四不像”的糟糕妥协。  

因此：

*   当 `alpha = 0.5` 时，本地数据分布与全局分布差异不大，客户端本身就有很多类别。因此，`cls_loss`和`contrastive_loss`的目标大致相同，梯度冲突较小。所以我们看到性能下降不明显，在训练后期甚至追平了。
*   当 `alpha = 0.05` 时，本地与全局的分布差异达到最大。`cls_loss`的目标变得极度专业化和狭隘，与`contrastive_loss`的全局化目标几乎正交。梯度冲突最大化，导致了灾难性的性能崩溃。
