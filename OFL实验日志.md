
## 2025/9/22
对于 memory bank 进行了实验，提供了三组实验数据，分别对应 `alpha=0.5`、`alpha=0.3` 和 `alpha=0.05` 三种不同的非独立同分布 (Non-IID) 程度，每组又包含了是否使用内存库 (Memory Bank) 的对比实验。数据见[memory_bank.txt](memory_bank.txt)

以下是对这些实验数据的分析，重点关注方案1中“改进负样本采样策略（动态负样本队列/内存库）”的效果：

### **实验设置概述**

*   **数据集：** CIFAR-10
*   **模型：** ResNet18
*   **客户端数量：** 5
*   **本地训练轮次 (local_epochs)：** 1
*   **联邦学习轮次 (num_rounds)：** 300 (日志中显示了前20轮)
*   **Non-IID程度 (`alpha`)：** 0.5 (较弱非IID), 0.3 (中等非IID), 0.05 (强非IID)
*   **对比学习温度 (`contrastive_temperature`)：** 0.5
*   **内存库大小 (`memory_bank_size`)：** 4096 (在使用内存库的实验中)

### **实验结果分析**

我们将提取每个实验配置在每轮结束后的 `The test accuracy (with prototype) of OneShotOurs+Ensemble` 指标，并进行对比。

#### **1. `alpha = 0.5` (较弱 Non-IID)**

| 轮次 (Round) | 无内存库准确率 (%) | 有内存库准确率 (%) | 差异 (有 - 无) |
| :----------: | :---------------: | :---------------: | :-----------: |
|      0       |       40.45       |       35.07       |    -5.38     |
|      1       |       47.04       |       42.10       |    -4.94     |
|      2       |       52.77       |       48.56       |    -4.21     |
|      3       |       58.05       |       52.72       |    -5.33     |
|      4       |       62.41       |       58.57       |    -3.84     |
|      5       |       64.60       |       61.31       |    -3.29     |
|      6       |       66.55       |       64.99       |    -1.56     |
|      7       |       69.01       |       64.88       |    -4.13     |
|      8       |       71.46       |       70.36       |    -1.10     |
|      9       |       72.82       |       69.93       |    -2.89     |
|      10      |       73.66       |       72.59       |    -1.07     |
|      11      |       75.68       |       72.42       |    -3.26     |
|      12      |       76.96       |       72.92       |    -4.04     |
|      13      |       76.74       |       74.59       |    -2.15     |
|      14      |       76.87       |       75.68       |    -1.19     |
|      15      |       77.92       |       76.15       |    -1.77     |
|      16      |       79.03       |       77.64       |    -1.39     |
|      17      |       79.81       |       78.54       |    -1.27     |
|      18      |       80.41       |       78.51       |    -1.90     |
|      19      |       80.41       |       79.28       |    -1.13     |
|      20      |       81.55       |       79.26       |    -2.29     |

在 `alpha=0.5` 这种较弱的 Non-IID 场景下，不使用内存库的基线模型表现略优于或与使用内存库的模型接近。初期，使用内存库的模型甚至表现更差。随着训练的进行，两者差距缩小，但基线模型仍保持微弱优势。这可能表明在数据异构性不那么极端时，引入内存库带来的额外复杂度或负样本噪声反而可能稍微影响模型的收敛速度或最终性能。

#### **2. `alpha = 0.3` (中等 Non-IID)**

| 轮次 (Round) | 无内存库准确率 (%) | 有内存库准确率 (%) | 差异 (有 - 无) |
| :----------: | :---------------: | :---------------: | :-----------: |
|      0       |       30.37       |       26.13       |    -4.24     |
|      1       |       40.74       |       35.91       |    -4.83     |
|      2       |       44.79       |       39.79       |    -5.00     |
|      3       |       49.66       |       45.86       |    -3.80     |
|      4       |       52.90       |       49.69       |    -3.21     |
|      5       |       57.02       |       52.77       |    -4.25     |
|      6       |       57.46       |       54.58       |    -2.88     |
|      7       |       61.51       |       57.85       |    -3.66     |
|      8       |       61.98       |       60.75       |    -1.23     |
|      9       |       64.46       |       61.55       |    -2.91     |
|      10      |       65.87       |       63.19       |    -2.68     |
|      11      |       67.28       |       64.71       |    -2.57     |
|      12      |       68.85       |       65.31       |    -3.54     |
|      13      |       69.77       |       65.27       |    -4.50     |
|      14      |       70.50       |       67.05       |    -3.45     |
|      15      |       70.28       |       67.25       |    -3.03     |
|      16      |       71.95       |       69.59       |    -2.36     |
|      17      |       72.11       |       68.49       |    -3.62     |
|      18      |       71.94       |       70.05       |    -1.89     |
|      19      |       73.89       |       72.00       |    -1.89     |
|      20      |       74.30       |       70.67       |    -3.63     |

在 `alpha=0.3` 的中等 Non-IID 场景下，情况与 `alpha=0.5` 类似，不使用内存库的基线模型在测试准确率上仍然保持着优势。虽然两个模型的准确率都在提高，但内存库的引入似乎没有带来预期的性能提升，反而导致了轻微的下降。这进一步印证了之前的观察。

#### **3. `alpha = 0.05` (强 Non-IID)**

| 轮次 (Round) | 无内存库准确率 (%) | 有内存库准确率 (%) | 差异 (有 - 无) |
| :----------: | :---------------: | :---------------: | :-----------: |
|      0       |       28.29       |       30.93       |     +2.64     |
|      1       |       34.50       |       30.00       |    -4.50     |
|      2       |       35.40       |       31.13       |    -4.27     |
|      3       |       38.19       |       35.44       |    -2.75     |
|      4       |       40.62       |       37.77       |    -2.85     |
|      5       |       41.16       |       37.44       |    -3.72     |
|      6       |       43.83       |       39.75       |    -4.08     |
|      7       |       45.99       |       42.00       |    -3.99     |
|      8       |       47.87       |       43.23       |    -4.64     |
|      9       |       49.95       |       44.67       |    -5.28     |
|      10      |       49.73       |       45.34       |    -4.39     |
|      11      |       50.03       |       46.69       |    -3.34     |
|      12      |       52.58       |       46.14       |    -6.44     |
|      13      |       52.62       |       49.79       |    -2.83     |
|      14      |       54.24       |       50.52       |    -3.72     |
|      15      |       54.47       |       52.01       |    -2.46     |
|      16      |       56.55       |       51.16       |    -5.39     |
|      17      |       56.79       |       52.59       |    -4.20     |
|      18      |       56.12       |       50.87       |    -5.25     |
|      19      |       58.10       |       51.78       |    -6.32     |
|      20      |       57.84       |       52.14       |    -5.70     |

在 `alpha=0.05` 这种最强的 Non-IID 场景下，虽然在第0轮（初始化阶段）使用内存库的模型表现稍好，但在随后的训练中，不使用内存库的基线模型迅速反超，并持续保持明显的优势。两者的差距在某些轮次甚至超过5-6个百分点，这表明在当前设置下，内存库并没有有效地缓解强 Non-IID 数据带来的挑战，反而可能加剧了性能下降。

### **总结和初步结论**

针对 FAFI 框架并采用“改进负样本采样策略（动态负样本队列/内存库）”这一优化方案，在 CIFAR-10 数据集、ResNet18 模型以及 `alpha` 分别为 0.5、0.3 和 0.05 的 Non-IID 设置下，**引入内存库似乎未能带来性能提升，反而导致了测试准确率的下降。** 尤其是在数据异构性较强 (`alpha=0.05`) 的情况下，性能差距更为显著。

让我们来深入剖析这一现象的成因。其核心在于一个关键概念：**负样本的“多样性”陷阱与“分布失配灾难”**。

### 核心原因：内存库放大了本地数据偏见，而非引入了全局多样性

我们期望的是**全局类别多样性**（即包含来自所有类别的数据），而该实现提供的仅仅是**时间上的多样性**（即包含了来自历史批次的样本）。在严格的 One-shot FL 隔离训练下，这两者是完全不同的。最终，内存库非但没有缓解模型不一致性，反而通过强化本地的偏见，极大地加剧了这个问题。

---

实验数据印证了上述理论：

*   **`alpha = 0.5` (较弱 Non-IID)**:
    *   每个客户端的数据分布虽然有偏见，但仍然包含了不少类别。
    *   因此，本地内存库中也包含了相对多样的类别。
    *   它没有引入太多全局知识，但也没有造成毁灭性的偏见放大。性能下降很可能是由于**内存库的噪声**（例如，早期训练时存入的不成熟特征）或**更新延迟**等次要因素造成的。

*   **`alpha = 0.05` (强 Non-IID)**:
    *   每个客户端的数据只包含极少数几个类别。
    *   本地内存库变成了本地偏见的**“回音室”和“放大器”**。
    *   模型被强制进行“过度专业化”训练，完全丧失了对未见类别的泛化能力，导致特征空间严重不一致。
    *   聚合后的全局模型性能因此急剧下降，造成了您观察到的巨大性能鸿沟。

---

### 对代码实现的进一步分析

1.  **内存库的初始化**: `memory_bank = torch.randn(...)`。在训练的最开始，内存库里是纯粹的随机噪声。模型最初的几次迭代是在与这些无意义的噪声进行对比，这可能导致了训练初期的不稳定和性能下降，正如您在所有 `alpha` 值下都观察到的那样（第0轮准确率下降）。

2.  **内存库的更新机制**: 代码采用了简单的队列（FIFO）更新机制。这意味着内存库的内容总是反映了模型在**近期**从其**有偏数据**中学到的东西，它没有机制来引入外部的、全局的知识。

### 结论与后续改进方向

**结论**: 在严格的 One-shot FL 框架下，一个完全在客户端本地构建和维护的内存库，其本质是 **“本地知识的蓄水池”**，而非 **“全局知识的窗口”**。因此，它无法解决 Non-IID 带来的类别缺失问题，反而会因为强化局部监督信号而毒害全局模型的聚合。

**如何修复这个问题？（真正的方案一应该是什么样的）**

要让内存库起作用，它必须包含客户端本地所缺乏的信息。这要求我们必须打破客户端的“信息孤岛”。

1.  **引入公共数据进行预填充 (One-shot 友好)**:
    *   在联邦学习开始**之前**，服务器可以使用一个小的、公开的数据集（例如，一个不含隐私的、类别丰富的标准数据集）来训练一个“教师模型”。
    *   服务器提取这个公开数据集在教师模型下的特征，形成一个**固定的、类别丰富的“公共负样本库”**。
    *   在 `OneshotOurs` 开始时，服务器将这个**公共负样本库一次性下发**给所有客户端。
    *   客户端在本地训练时，使用这个固定的公共库作为负样本源，而不是自己从零构建。
    *   **优点**: 这符合 One-shot 的“单轮交互”原则，并且为所有客户端提供了一个统一的、多样化的负样本参考系，有助于对齐它们的特征空间。

2.  **硬负样本挖掘 (Hard Negative Mining)**:
    *   即便使用了有偏的本地内存库，我们也可以让它更有效。与其将所有负样本同等对待，不如让模型专注于那些**最难区分的负样本**（即与锚点特征最相似的负样本）。
    *   在计算对比损失时，不是与内存库中所有样本对比，而是选择性地与“硬负样本”进行对比。这会迫使模型学习更具判别力的细粒度特征，可能在一定程度上缓解过拟合到简单负样本的问题。这需要修改 `SupConLoss` 函数。

3.  **调整超参数**:
    *   当负样本的数量和质量发生巨大变化时（例如从几十个 batch 内负样本增加到4096个库内负样本），对比学习的**温度系数 `temperature`** 变得至关重要。`temperature=0.5` 可能太高了，导致所有负样本的区分度都很低。对于更大、可能更难的负样本集，通常需要更小的温度值（如0.07-0.2）来增强模型的判别力。
