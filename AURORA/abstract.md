# FLARE: Federated Learning with Autonomous Regularization and Evidence-based Alignment

**Abstract**
~~ One-shot Federated Learning (OFL) represents the frontier of communication efficiency in distributed machine learning, ~~ allowing clients to upload their locally trained models only once. However, in non-IID scenarios, the lack of continuous communication leads to severe *model inconsistency*, where local models diverge in feature space, rendering server-side aggregation ineffective. While recent state-of-the-art methods like FAFI have mitigated this by enhancing local feature extraction via static self-supervision, they overlook the dynamic tension between *global alignment* and *local adaptation* throughout the training process. A fixed balance between these conflicting objectives often leads to sub-optimal convergence or training instability.

In this work, we propose **FLARE** (**F**ederated **L**earning with **A**utonomous **R**egularization and **E**vidence-based Alignment), a novel OFL framework that automates the coordination of local and global learning objectives. FLARE introduces two key innovations: (1) It employs a fixed **Simplex Equiangular Tight Frame (ETF)** as an explicit geometric anchor for global consistency; (2) It incorporates a **meta-curriculum learning mechanism** derived from uncertainty weighting and gradient detachment. This allows the model to *autonomously learn* an optimal annealing schedule—prioritizing global consensus in early stages and shifting to local adaptation in later stages—without manual hyperparameter tuning. Furthermore, we design a Bayesian prior-based regularization term to ensure robustness under extreme heterogeneity. Extensive experiments on CIFAR-10/100 and SVHN demonstrate that FLARE significantly outperforms existing baselines, achieving SOTA performance while maintaining the strict one-shot constraint.

---

**1. Introduction**

Federated Learning (FL) has emerged as a de facto paradigm for collaborative machine learning under privacy constraints (McMahan et al., 2017). Despite its success, traditional multi-round FL suffers from prohibitive communication overhead, especially when deploying large-scale models over bandwidth-constrained edge networks. **One-shot Federated Learning (OFL)** pushes communication efficiency to its limit by restricting the client-server interaction to a single round (Guha et al., 2019). In OFL, clients train locally until convergence and upload their models to the server for a one-time aggregation.

However, this "train-then-merge" paradigm faces a critical challenge: **Model Inconsistency** (Zeng et al., 2025). Under Non-IID data distributions, local models optimizing solely for local tasks tend to drift into disparate regions of the feature space. Without periodic synchronization to correct these drifts, the aggregated global model often suffers from performance degradation, a phenomenon known as the "garbage-in, garbage-out" pitfall.

Recent advancements, most notably **FAFI** (Zeng et al., 2025), have made significant strides in mitigating this issue. By augmenting local training with self-supervised contrastive learning and prototype alignment, FAFI encourages local models to learn more generalized features. While effective, FAFI and similar approaches typically treat the local training objective as a **static** weighted sum of local supervision and alignment regularization. We argue that this static treatment is fundamentally sub-optimal. The training dynamics of a local client involve a temporal dichotomy:
*   **Early Stage:** The model requires strong guidance to align with a global consensus (avoiding early overfitting to local bias).
*   **Late Stage:** The model requires freedom to refine its decision boundaries based on specific local data characteristics (local adaptation).
A fixed regularization weight ($\lambda$) fails to satisfy both needs simultaneously: a small $\lambda$ leads to early divergence, while a large $\lambda$ hinders final convergence and adaptation. While manual annealing schedules (e.g., linear decay) can alleviate this, they introduce sensitive hyperparameters that require expensive tuning for each dataset and heterogeneity level.

To bridge this gap, we present **FLARE**, an autonomous framework that transforms the OFL training process from a static optimization problem into a dynamic, self-regulating meta-curriculum. FLARE is built upon three pillars:

1.  **Explicit Global Anchoring:** Instead of relying on implicit alignment, we anchor all clients to a pre-defined, geometrically optimal **Simplex Equiangular Tight Frame (ETF)** classifier. This provides a consistent "lighthouse" for all clients in the chaotic feature space.
2.  **Autonomous Regularization:** We propose a novel optimization strategy inspired by homoscedastic uncertainty weighting (Kendall et al., 2018). By decoupling the gradient flows of model parameters and weighting parameters, FLARE allows the client model to *autonomously learn* the relative importance of the alignment loss. This results in an emergent annealing behavior—the model naturally starts with high alignment focus and gradually shifts attention to local tasks as its certainty increases.
3.  **Robustness via Safety Valve:** We identify that in scenarios with extreme data heterogeneity (e.g., SVHN with $\alpha=0.05$), the uncertainty-based mechanism can lead to numerical instability (the "exploding $\lambda$" problem). We introduce a robust regularization term based on Bayesian priors, effectively acting as a "safety valve" that stabilizes the adaptive weights without compromising their flexibility.

We empirically validate FLARE on multiple benchmarks including CIFAR-10, CIFAR-100, and SVHN under varying degrees of heterogeneity. Our results show that FLARE not only consistently outperforms state-of-the-art methods (including FAFI) but also eliminates the need for manual hyperparameter search, offering a robust and "plug-and-play" solution for practical One-shot Federated Learning.

To summarize, our main contributions are:
*   We identify the limitations of static regularization in existing OFL methods and propose the concept of **dynamic task attenuation** for balancing global alignment and local adaptation.
*   We develop **FLARE**, a theoretically grounded framework that leverages uncertainty weighting and gradient detachment to autonomously learn an optimal alignment schedule.
*   We introduce a direct regularization mechanism for adaptive weights, ensuring the algorithm's robustness in extreme non-IID scenarios where prior adaptive methods fail.
*   Extensive experiments demonstrate that FLARE achieves state-of-the-art accuracy and model consistency, verifying the effectiveness of our autonomous design.
